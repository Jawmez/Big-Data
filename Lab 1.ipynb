{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "James Reed <br>\n",
    "9/7/16 <br>\n",
    "Lab 1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statistics  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import datetime; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "west median = 1573.5\n",
      "east median = 1648.0\n",
      "west mean = 1497.5666666666666\n",
      "east mean = 1540.4333333333334\n",
      "The max number in west is 2270\n",
      "The max number in east is 2361\n",
      "The index for the max of west is 22\n",
      "The index for the max of east is 21\n",
      "The index for the max combined number is 22\n",
      "The date for this index is 9/23/15\n",
      "The day of the week for the max number is Wedensday\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "#I imported statistics again becase for some reason the code did not recognize the imported\n",
    "#statistics in the first block. \n",
    "data_file = open(\"FreBridge1.csv\", \"r\");\n",
    "data_list = [];\n",
    "for ii in data_file:\n",
    "    data_list.append(ii);\n",
    "\n",
    "del data_list[0];\n",
    "#create empty lists for westbound and eastbound bikes\n",
    "west = [];\n",
    "east = [];    \n",
    "for jj in range(len(data_list)):\n",
    "    #make into a list of lists of just numbers\n",
    "    data_list[jj] = data_list[jj].split(\",\");\n",
    "    #add data to specific lists for west and east\n",
    "    west.append(int(data_list[jj][1]));\n",
    "    east.append(int(data_list[jj][2]));\n",
    "\n",
    "#print(west);\n",
    "#print(east);\n",
    "\n",
    "#print(\" west mode =\", statistics.mode(west));\n",
    "#print(\"east mode =\", statistics.mode(east)); \n",
    "print(\"west median =\", statistics.median(west));\n",
    "print(\"east median =\", statistics.median(east)); \n",
    "print(\"west mean =\", statistics.mean(west));\n",
    "print(\"east mean =\", statistics.mean(east)); \n",
    "\n",
    "print(\"The max number in west is\", max(west));\n",
    "print(\"The max number in east is\", max(east));\n",
    "print(\"The index for the max of west is\", west.index(max(west))); \n",
    "print(\"The index for the max of east is\", east.index(max(east)));\n",
    "\n",
    "big_data = []; \n",
    "for x in range (len(west)):\n",
    "    big_data.append(west[x] + east[x]); \n",
    "\n",
    "print(\"The index for the max combined number is\", big_data.index(max(big_data))); \n",
    "final_max = (data_list[big_data.index(max(big_data))][0]);\n",
    "print(\"The date for this index is\", final_max); \n",
    "\n",
    "blank_list = []; \n",
    "for x in range(len(big_data)):\n",
    "    one = (x + 2)%8 \n",
    "    if(one == 1):\n",
    "        blank_list.append(\"Monday\"); \n",
    "    elif(one == 2):\n",
    "        blank_list.append(\"Tuesday\"); \n",
    "    elif(one == 3):\n",
    "        blank_list.append(\"Wedensday\"); \n",
    "    elif(one == 4):\n",
    "        blank_list.append(\"Thursday\"); \n",
    "    elif(one == 5):\n",
    "        blank_list.append(\"Friday\");\n",
    "    elif(one == 6):\n",
    "        blank_list.append(\"Saturday\"); \n",
    "    elif(one == 7):\n",
    "        blank_list.append(\"Sunday\"); \n",
    "\n",
    "print(\"The day of the week for the max number is\", blank_list[22]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Analysis for Part One:\n",
    "\n",
    "We computed the mean, median and mode for the two data sets above (east and west). In real world terms, the mean is a represntation of the average of all of the points in the data. It reveals constant and reaccuring trends in the data. In large data sets (like the one we were given above), it is useful for generalizing the trends in data. In smaller data sets, it can be less reliable as outliers can have a larger effect in skewing the average. The median finds a middle number in the data set. This is helpful when dealing with data sets that may have many outliers. Because this was a larger data set with not that many outliers, the mean and medians where relatively close together for both sets of data. The mode finds the number that is repeated the most in the data sets. Again, this can be helpful for finding reaccuring trends in data sets (this is number specific). Although the finding the mode can be useful in some data sets, it was useless in these data sets as there where no repeating numbers in either data set. \n",
    "\n",
    "The mean seems to give the most information in this data set. This is becase we are looking for an average and similarity in data and that is what the mean calculates for. \n",
    "\n",
    "I found that Wednesday had the highest number of crossings. I was able to find this by first finding which date had the highest number of crossings. Once I figured out which day had the highest number of crossings, I found the index of the date. I then creating a new list of dates (starting at Tuesday because the first was on a Tuesday), and found the day of the week that was at the same index as the date. This date happend to be wednesday. I was able to check my work by comparing my answer to a calender. It was correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average for the Lists: 2784\n",
      "mean of fridays: 2748\n",
      "Standard Deviation for Full List: 1392\n",
      "standard Deviation for Friday: 1411\n",
      "We are 68% confident that the data is within 1,392 and 4,176 crossings, using the entire data set\n",
      "We are 68% confident that the data is within 1,337 and 4,159 crossings, using the friday data set\n"
     ]
    }
   ],
   "source": [
    "data_file_two = open(\"FreBridge2.csv\", \"r\");\n",
    "\n",
    "x_axis = []; \n",
    "for ii in data_file_two:\n",
    "    x_axis.append(ii); \n",
    "del x_axis[0];\n",
    "#create empty lists for westbound and eastbound bikes\n",
    "west_two = [];\n",
    "east_two = [];    \n",
    "for jj in range(len(x_axis)):\n",
    "    #make into a list of lists of just numbers\n",
    "    x_axis[jj] = x_axis[jj].split(\",\");\n",
    "    #add data to specific lists for west and east\n",
    "    west_two.append(int(x_axis[jj][1]));\n",
    "    east_two.append(int(x_axis[jj][2]));\n",
    "\n",
    "big_data_two = []; \n",
    "for x in range (len(west_two)):\n",
    "    big_data_two.append(west_two[x] + east_two[x]); \n",
    "\n",
    "print(\"Average for the Lists:\", int(statistics.mean(big_data_two)));\n",
    "#print(big_data_two);\n",
    "\n",
    "friday_list = []; \n",
    "for aa in range(len(big_data_two)):\n",
    "    one = (aa + 3)%8\n",
    "    if(one == 5):\n",
    "        friday_list.append(big_data_two[aa]); \n",
    "\n",
    "#print(\"friday list:\", friday_list);\n",
    "print(\"mean of fridays:\", int(statistics.mean(friday_list))); \n",
    "\n",
    "date_list = []; \n",
    "for x in range(len(big_data_two)):\n",
    "    one = (x + 3)%8 \n",
    "    if(one == 1):\n",
    "        date_list.append(\"Monday\"); \n",
    "    elif(one == 2):\n",
    "        date_list.append(\"Tuesday\"); \n",
    "    elif(one == 3):\n",
    "        date_list.append(\"Wedensday\"); \n",
    "    elif(one == 4):\n",
    "        date_list.append(\"Thursday\"); \n",
    "    elif(one == 5):\n",
    "        date_list.append(\"Friday\");\n",
    "    elif(one == 6):\n",
    "        date_list.append(\"Saturday\"); \n",
    "    elif(one == 7):\n",
    "        date_list.append(\"Sunday\"); \n",
    "#print(date_list);\n",
    "\n",
    "stdev = int(statistics.stdev(big_data_two)); \n",
    "stdevfri = int(statistics.stdev(friday_list));\n",
    "\n",
    "print(\"Standard Deviation for Full List:\", stdev);\n",
    "print(\"standard Deviation for Friday:\", stdevfri);\n",
    "\n",
    "print(\"We are 68% confident that the data is within 1,392 and 4,176 crossings, using the entire data set\");\n",
    "print(\"We are 68% confident that the data is within 1,337 and 4,159 crossings, using the friday data set\"); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis for Part Two:\n",
    "\n",
    "In this second section, I took the means of the entire data set and specifically friday. I took the mean of crossings on friday because we are predicting a range of numbers for a day that will be on a friday. \n",
    "\n",
    "I used standard deviations when coming up with a prediciton because they allow me to have a prediction confidence precent (in this case 68%), and also have a range of data points, hence the standard deviation. \n",
    "\n",
    "I think it could also be intresting to calculate standard deviations using a median. It would be intresting to see how this would change the predictions. After calculating the standard deviations, I found that for both set, the deviation seemed to be around 1,300 to 1,400 in either direction (for one deviation). The deviations are in the 1,000s because all of the dates have more than 1,000 crossings per day. My calculations and solutions are written in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "In conclusion, I found that in this data set, both the median and the mean could be used to help come up with future predicitons. Due to the size of the data set, the deviations where in the 1000s. In my prediciton methods, I took the means and deviaitons of both a list containing fridays and a list with all of the data points. Although these lists where relativly similar, they where slightly  different in mean and deviation size. Although we are predicting a future friday so using a friday list would make sense, A list containing all data points may be more reliable as it has a larger sample size than the friday list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
